{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMo1O/aeIvTwa3mx879aP+c"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N6P6aMmSDs90","executionInfo":{"status":"ok","timestamp":1695355957996,"user_tz":300,"elapsed":979,"user":{"displayName":"Angel Nakkala","userId":"13968467036875532034"}},"outputId":"0413b022-ebfd-400f-c69a-66bcf45d5f1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n"]},{"cell_type":"code","source":["path_to_csv = '/content/gdrive/MyDrive/Colab Notebooks/diabetes.csv'\n"],"metadata":{"id":"Y3PpSC4HFv9d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import keras\n","import pandas\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","\n","# load dataset\n","from sklearn.model_selection import train_test_split\n","import pandas as pd\n","import numpy as np\n","\n","dataset = pd.read_csv(path_to_csv, header=None).values\n","\n","X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n","                                                    test_size=0.25, random_state=87)\n","np.random.seed(155)\n","my_first_nn = Sequential() # create model\n","my_first_nn.add(Dense(20, input_dim=8, activation='relu')) # hidden layer\n","my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n","my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n","my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n","                                     initial_epoch=0)\n","print(my_first_nn.summary())\n","print(my_first_nn.evaluate(X_test, Y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vYppr_UwGCaF","executionInfo":{"status":"ok","timestamp":1695363590489,"user_tz":300,"elapsed":7372,"user":{"displayName":"Angel Nakkala","userId":"13968467036875532034"}},"outputId":"94b75c4c-734a-4910-db51-7cd64a0dff74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","18/18 [==============================] - 2s 3ms/step - loss: 3.7410 - acc: 0.5556\n","Epoch 2/100\n","18/18 [==============================] - 0s 3ms/step - loss: 3.0136 - acc: 0.6024\n","Epoch 3/100\n","18/18 [==============================] - 0s 3ms/step - loss: 2.5335 - acc: 0.5816\n","Epoch 4/100\n","18/18 [==============================] - 0s 3ms/step - loss: 2.1542 - acc: 0.5799\n","Epoch 5/100\n","18/18 [==============================] - 0s 3ms/step - loss: 1.9270 - acc: 0.5990\n","Epoch 6/100\n","18/18 [==============================] - 0s 3ms/step - loss: 1.6754 - acc: 0.6042\n","Epoch 7/100\n","18/18 [==============================] - 0s 4ms/step - loss: 1.5052 - acc: 0.6111\n","Epoch 8/100\n","18/18 [==============================] - 0s 3ms/step - loss: 1.3992 - acc: 0.6146\n","Epoch 9/100\n","18/18 [==============================] - 0s 3ms/step - loss: 1.2542 - acc: 0.6198\n","Epoch 10/100\n","18/18 [==============================] - 0s 3ms/step - loss: 1.1728 - acc: 0.6250\n","Epoch 11/100\n","18/18 [==============================] - 0s 2ms/step - loss: 1.0955 - acc: 0.6198\n","Epoch 12/100\n","18/18 [==============================] - 0s 2ms/step - loss: 1.0433 - acc: 0.6233\n","Epoch 13/100\n","18/18 [==============================] - 0s 2ms/step - loss: 1.0047 - acc: 0.6337\n","Epoch 14/100\n","18/18 [==============================] - 0s 2ms/step - loss: 1.0027 - acc: 0.6215\n","Epoch 15/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.9181 - acc: 0.6372\n","Epoch 16/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.8925 - acc: 0.6406\n","Epoch 17/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.8747 - acc: 0.6198\n","Epoch 18/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.8548 - acc: 0.6319\n","Epoch 19/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7988 - acc: 0.6632\n","Epoch 20/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7796 - acc: 0.6510\n","Epoch 21/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7715 - acc: 0.6528\n","Epoch 22/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.8482 - acc: 0.6267\n","Epoch 23/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7606 - acc: 0.6406\n","Epoch 24/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7251 - acc: 0.6806\n","Epoch 25/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7137 - acc: 0.6615\n","Epoch 26/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6886 - acc: 0.6823\n","Epoch 27/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6788 - acc: 0.6806\n","Epoch 28/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6813 - acc: 0.6684\n","Epoch 29/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6584 - acc: 0.6858\n","Epoch 30/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6593 - acc: 0.6684\n","Epoch 31/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6532 - acc: 0.6840\n","Epoch 32/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6431 - acc: 0.6806\n","Epoch 33/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6331 - acc: 0.6910\n","Epoch 34/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6330 - acc: 0.6875\n","Epoch 35/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6453 - acc: 0.6719\n","Epoch 36/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6332 - acc: 0.6875\n","Epoch 37/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6181 - acc: 0.6892\n","Epoch 38/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6313 - acc: 0.6858\n","Epoch 39/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6222 - acc: 0.6701\n","Epoch 40/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6373 - acc: 0.6719\n","Epoch 41/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6239 - acc: 0.6788\n","Epoch 42/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6044 - acc: 0.6892\n","Epoch 43/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5887 - acc: 0.6910\n","Epoch 44/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5925 - acc: 0.6962\n","Epoch 45/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6039 - acc: 0.7066\n","Epoch 46/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5851 - acc: 0.7014\n","Epoch 47/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5808 - acc: 0.6997\n","Epoch 48/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5952 - acc: 0.6910\n","Epoch 49/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5841 - acc: 0.6997\n","Epoch 50/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5941 - acc: 0.6910\n","Epoch 51/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5850 - acc: 0.7083\n","Epoch 52/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5981 - acc: 0.6997\n","Epoch 53/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6176 - acc: 0.6910\n","Epoch 54/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5992 - acc: 0.6997\n","Epoch 55/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5905 - acc: 0.7031\n","Epoch 56/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6026 - acc: 0.6892\n","Epoch 57/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5724 - acc: 0.7066\n","Epoch 58/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5627 - acc: 0.7101\n","Epoch 59/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5588 - acc: 0.7240\n","Epoch 60/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5794 - acc: 0.7014\n","Epoch 61/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5542 - acc: 0.7118\n","Epoch 62/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5626 - acc: 0.6944\n","Epoch 63/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5633 - acc: 0.7101\n","Epoch 64/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5745 - acc: 0.7118\n","Epoch 65/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5919 - acc: 0.6997\n","Epoch 66/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5574 - acc: 0.7101\n","Epoch 67/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5605 - acc: 0.7153\n","Epoch 68/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5801 - acc: 0.6997\n","Epoch 69/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5994 - acc: 0.6753\n","Epoch 70/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5722 - acc: 0.7188\n","Epoch 71/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5498 - acc: 0.7396\n","Epoch 72/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5461 - acc: 0.7292\n","Epoch 73/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5656 - acc: 0.7049\n","Epoch 74/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5761 - acc: 0.7257\n","Epoch 75/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5588 - acc: 0.7101\n","Epoch 76/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5463 - acc: 0.7240\n","Epoch 77/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5547 - acc: 0.7101\n","Epoch 78/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5436 - acc: 0.7188\n","Epoch 79/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5534 - acc: 0.7118\n","Epoch 80/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5555 - acc: 0.7257\n","Epoch 81/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5557 - acc: 0.7413\n","Epoch 82/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5456 - acc: 0.7361\n","Epoch 83/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5631 - acc: 0.7222\n","Epoch 84/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5532 - acc: 0.7222\n","Epoch 85/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5429 - acc: 0.7222\n","Epoch 86/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5467 - acc: 0.7240\n","Epoch 87/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5519 - acc: 0.7205\n","Epoch 88/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5312 - acc: 0.7292\n","Epoch 89/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5322 - acc: 0.7344\n","Epoch 90/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - acc: 0.7222\n","Epoch 91/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5378 - acc: 0.7309\n","Epoch 92/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5332 - acc: 0.7222\n","Epoch 93/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5444 - acc: 0.7344\n","Epoch 94/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5294 - acc: 0.7240\n","Epoch 95/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5370 - acc: 0.7222\n","Epoch 96/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5319 - acc: 0.7431\n","Epoch 97/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5269 - acc: 0.7292\n","Epoch 98/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5312 - acc: 0.7188\n","Epoch 99/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - acc: 0.7483\n","Epoch 100/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - acc: 0.7378\n","Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_8 (Dense)             (None, 20)                180       \n","                                                                 \n"," dense_9 (Dense)             (None, 1)                 21        \n","                                                                 \n","=================================================================\n","Total params: 201 (804.00 Byte)\n","Trainable params: 201 (804.00 Byte)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","6/6 [==============================] - 0s 4ms/step - loss: 0.6137 - acc: 0.7188\n","[0.6137073636054993, 0.71875]\n"]}]},{"cell_type":"code","source":["import keras\n","import pandas as pd\n","import numpy as np\n","from keras.models import Sequential\n","from keras.layers import Dense, Activation\n","from sklearn.model_selection import train_test_split\n","\n","# load dataset\n","path_to_csv = '/content/gdrive/MyDrive/Colab Notebooks/diabetes.csv'\n","dataset = pd.read_csv(path_to_csv, header=None).values\n","\n","# split dataset into training and test sets\n","X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,0:8], dataset[:,8],\n","                                                    test_size=0.25, random_state=87)\n","\n","# define the model\n","np.random.seed(155)\n","my_second_nn = Sequential()\n","my_second_nn.add(Dense(20, input_dim=8, activation='relu'))\n","my_second_nn.add(Dense(20, input_dim=8,activation='relu'))\n","my_second_nn.add(Dense(20, input_dim=8,activation='relu'))\n","my_second_nn.add(Dense(1, activation='sigmoid'))\n","my_second_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# train the model\n","my_second_nn_fitted= my_second_nn.fit(X_train, Y_train, epochs=100,\n","                                     initial_epoch=0)\n","\n","\n","# evaluate the model on the test set\n","score = my_second_nn.evaluate(X_test, Y_test, batch_size=64)\n","print(my_second_nn.summary())\n","print(\"Test accuracy:\", score[1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ySg2EGkYRa_Z","executionInfo":{"status":"ok","timestamp":1695363613246,"user_tz":300,"elapsed":7726,"user":{"displayName":"Angel Nakkala","userId":"13968467036875532034"}},"outputId":"e26fdfd7-9570-4755-8be6-8bf159d95569"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","18/18 [==============================] - 1s 2ms/step - loss: 3.0600 - accuracy: 0.5642\n","Epoch 2/100\n","18/18 [==============================] - 0s 2ms/step - loss: 1.4407 - accuracy: 0.5260\n","Epoch 3/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.9814 - accuracy: 0.5799\n","Epoch 4/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.8158 - accuracy: 0.5903\n","Epoch 5/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7978 - accuracy: 0.6267\n","Epoch 6/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.8158 - accuracy: 0.6233\n","Epoch 7/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.9027 - accuracy: 0.6111\n","Epoch 8/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7521 - accuracy: 0.6215\n","Epoch 9/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.7618 - accuracy: 0.6372\n","Epoch 10/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6453 - accuracy: 0.6788\n","Epoch 11/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6529 - accuracy: 0.6267\n","Epoch 12/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6883 - accuracy: 0.6493\n","Epoch 13/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.7071 - accuracy: 0.6319\n","Epoch 14/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.6562\n","Epoch 15/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.6545\n","Epoch 16/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6719\n","Epoch 17/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6840\n","Epoch 18/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.7286 - accuracy: 0.6719\n","Epoch 19/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.9501 - accuracy: 0.6406\n","Epoch 20/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6509 - accuracy: 0.6806\n","Epoch 21/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6092 - accuracy: 0.6701\n","Epoch 22/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.7066\n","Epoch 23/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5938 - accuracy: 0.7170\n","Epoch 24/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7153\n","Epoch 25/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.6788\n","Epoch 26/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6962\n","Epoch 27/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6384 - accuracy: 0.7014\n","Epoch 28/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.7205\n","Epoch 29/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7344\n","Epoch 30/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5701 - accuracy: 0.7049\n","Epoch 31/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7049\n","Epoch 32/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6807 - accuracy: 0.6944\n","Epoch 33/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.6840\n","Epoch 34/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.7014\n","Epoch 35/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.6112 - accuracy: 0.7135\n","Epoch 36/100\n","18/18 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7361\n","Epoch 37/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7205\n","Epoch 38/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.7257\n","Epoch 39/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5671 - accuracy: 0.7274\n","Epoch 40/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6035 - accuracy: 0.7135\n","Epoch 41/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5966 - accuracy: 0.7170\n","Epoch 42/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.7101\n","Epoch 43/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.6979\n","Epoch 44/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.7656\n","Epoch 45/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5588 - accuracy: 0.7292\n","Epoch 46/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7257\n","Epoch 47/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6036 - accuracy: 0.7153\n","Epoch 48/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.6962\n","Epoch 49/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5948 - accuracy: 0.7240\n","Epoch 50/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5428 - accuracy: 0.7257\n","Epoch 51/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5617 - accuracy: 0.7274\n","Epoch 52/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.7309\n","Epoch 53/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7396\n","Epoch 54/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.7517\n","Epoch 55/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7431\n","Epoch 56/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5463 - accuracy: 0.7535\n","Epoch 57/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5429 - accuracy: 0.7361\n","Epoch 58/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7500\n","Epoch 59/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7517\n","Epoch 60/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7465\n","Epoch 61/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.7535\n","Epoch 62/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.6596 - accuracy: 0.6944\n","Epoch 63/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5450 - accuracy: 0.7465\n","Epoch 64/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5277 - accuracy: 0.7483\n","Epoch 65/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5410 - accuracy: 0.7483\n","Epoch 66/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5171 - accuracy: 0.7604\n","Epoch 67/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7465\n","Epoch 68/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5113 - accuracy: 0.7604\n","Epoch 69/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5271 - accuracy: 0.7535\n","Epoch 70/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5340 - accuracy: 0.7535\n","Epoch 71/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7535\n","Epoch 72/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5591 - accuracy: 0.7240\n","Epoch 73/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.6292 - accuracy: 0.7118\n","Epoch 74/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.7569\n","Epoch 75/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5329 - accuracy: 0.7569\n","Epoch 76/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7517\n","Epoch 77/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7760\n","Epoch 78/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5112 - accuracy: 0.7569\n","Epoch 79/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7691\n","Epoch 80/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5305 - accuracy: 0.7326\n","Epoch 81/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7205\n","Epoch 82/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.7569\n","Epoch 83/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7691\n","Epoch 84/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7500\n","Epoch 85/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7344\n","Epoch 86/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7396\n","Epoch 87/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4907 - accuracy: 0.7691\n","Epoch 88/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.7431\n","Epoch 89/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5516 - accuracy: 0.7413\n","Epoch 90/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.7569\n","Epoch 91/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7517\n","Epoch 92/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5086 - accuracy: 0.7604\n","Epoch 93/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7743\n","Epoch 94/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.7639\n","Epoch 95/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.4909 - accuracy: 0.7552\n","Epoch 96/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7622\n","Epoch 97/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7622\n","Epoch 98/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.7656\n","Epoch 99/100\n","18/18 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7691\n","Epoch 100/100\n","18/18 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7708\n","3/3 [==============================] - 0s 5ms/step - loss: 0.5752 - accuracy: 0.7396\n","Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_10 (Dense)            (None, 20)                180       \n","                                                                 \n"," dense_11 (Dense)            (None, 20)                420       \n","                                                                 \n"," dense_12 (Dense)            (None, 20)                420       \n","                                                                 \n"," dense_13 (Dense)            (None, 1)                 21        \n","                                                                 \n","=================================================================\n","Total params: 1041 (4.07 KB)\n","Trainable params: 1041 (4.07 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Test accuracy: 0.7395833134651184\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","# Load dataset\n","data = load_breast_cancer()\n","\n","# Split dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(data.data, data.target,\n","                                                    test_size=0.25, random_state=87)\n","\n","# Normalize data\n","sc = StandardScaler()\n","X_train_norm = sc.fit_transform(X_train)\n","X_test_norm = sc.transform(X_test)\n","\n","# Create model\n","np.random.seed(155)\n","model = Sequential()\n","model.add(Dense(20, input_dim=30, activation='relu'))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# Train model\n","model.fit(X_train_norm, y_train, epochs=100, initial_epoch=0)\n","\n","# Evaluate model on testing set\n","loss, accuracy = model.evaluate(X_test_norm, y_test)\n","print(model.summary())\n","print(\"Loss:\", loss)\n","print(\"Accuracy:\", accuracy)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6uNNeMpPiWiM","executionInfo":{"status":"ok","timestamp":1695363506968,"user_tz":300,"elapsed":12393,"user":{"displayName":"Angel Nakkala","userId":"13968467036875532034"}},"outputId":"8839b5f7-20c2-475c-c935-1578f2e5750d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","14/14 [==============================] - 3s 6ms/step - loss: 0.5810 - accuracy: 0.7629\n","Epoch 2/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.8944\n","Epoch 3/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.3076 - accuracy: 0.9272\n","Epoch 4/100\n","14/14 [==============================] - 0s 10ms/step - loss: 0.2481 - accuracy: 0.9460\n","Epoch 5/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.2088 - accuracy: 0.9554\n","Epoch 6/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.1828 - accuracy: 0.9601\n","Epoch 7/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.1630 - accuracy: 0.9648\n","Epoch 8/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.1486 - accuracy: 0.9695\n","Epoch 9/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9695\n","Epoch 10/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.1273 - accuracy: 0.9695\n","Epoch 11/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.1194 - accuracy: 0.9695\n","Epoch 12/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.1126 - accuracy: 0.9695\n","Epoch 13/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.1068 - accuracy: 0.9695\n","Epoch 14/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.1016 - accuracy: 0.9718\n","Epoch 15/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9742\n","Epoch 16/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.0932 - accuracy: 0.9742\n","Epoch 17/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9742\n","Epoch 18/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9765\n","Epoch 19/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9765\n","Epoch 20/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9812\n","Epoch 21/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0784 - accuracy: 0.9859\n","Epoch 22/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0761 - accuracy: 0.9859\n","Epoch 23/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0738 - accuracy: 0.9859\n","Epoch 24/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0718 - accuracy: 0.9859\n","Epoch 25/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0697 - accuracy: 0.9859\n","Epoch 26/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0680 - accuracy: 0.9836\n","Epoch 27/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0663 - accuracy: 0.9836\n","Epoch 28/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9836\n","Epoch 29/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9836\n","Epoch 30/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9836\n","Epoch 31/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.0603 - accuracy: 0.9836\n","Epoch 32/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.9836\n","Epoch 33/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9836\n","Epoch 34/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.0569 - accuracy: 0.9859\n","Epoch 35/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.0557 - accuracy: 0.9859\n","Epoch 36/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9859\n","Epoch 37/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9859\n","Epoch 38/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9883\n","Epoch 39/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0516 - accuracy: 0.9883\n","Epoch 40/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9883\n","Epoch 41/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0497 - accuracy: 0.9883\n","Epoch 42/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.0487 - accuracy: 0.9906\n","Epoch 43/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9930\n","Epoch 44/100\n","14/14 [==============================] - 0s 10ms/step - loss: 0.0474 - accuracy: 0.9930\n","Epoch 45/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.0465 - accuracy: 0.9930\n","Epoch 46/100\n","14/14 [==============================] - 0s 10ms/step - loss: 0.0456 - accuracy: 0.9930\n","Epoch 47/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.0449 - accuracy: 0.9930\n","Epoch 48/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.9930\n","Epoch 49/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0432 - accuracy: 0.9930\n","Epoch 50/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.0425 - accuracy: 0.9930\n","Epoch 51/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.0420 - accuracy: 0.9930\n","Epoch 52/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9930\n","Epoch 53/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0408 - accuracy: 0.9930\n","Epoch 54/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9930\n","Epoch 55/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0394 - accuracy: 0.9930\n","Epoch 56/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0390 - accuracy: 0.9930\n","Epoch 57/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 0.9930\n","Epoch 58/100\n","14/14 [==============================] - 0s 6ms/step - loss: 0.0380 - accuracy: 0.9930\n","Epoch 59/100\n","14/14 [==============================] - 0s 7ms/step - loss: 0.0374 - accuracy: 0.9930\n","Epoch 60/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.0369 - accuracy: 0.9930\n","Epoch 61/100\n","14/14 [==============================] - 0s 9ms/step - loss: 0.0365 - accuracy: 0.9930\n","Epoch 62/100\n","14/14 [==============================] - 0s 18ms/step - loss: 0.0358 - accuracy: 0.9930\n","Epoch 63/100\n","14/14 [==============================] - 0s 16ms/step - loss: 0.0355 - accuracy: 0.9930\n","Epoch 64/100\n","14/14 [==============================] - 0s 14ms/step - loss: 0.0350 - accuracy: 0.9930\n","Epoch 65/100\n","14/14 [==============================] - 0s 10ms/step - loss: 0.0345 - accuracy: 0.9930\n","Epoch 66/100\n","14/14 [==============================] - 0s 8ms/step - loss: 0.0342 - accuracy: 0.9930\n","Epoch 67/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.0338 - accuracy: 0.9930\n","Epoch 68/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0333 - accuracy: 0.9930\n","Epoch 69/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0330 - accuracy: 0.9930\n","Epoch 70/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9930\n","Epoch 71/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0321 - accuracy: 0.9930\n","Epoch 72/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0317 - accuracy: 0.9930\n","Epoch 73/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9930\n","Epoch 74/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9930\n","Epoch 75/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0307 - accuracy: 0.9930\n","Epoch 76/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9930\n","Epoch 77/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9930\n","Epoch 78/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9930\n","Epoch 79/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9930\n","Epoch 80/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0290 - accuracy: 0.9930\n","Epoch 81/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0289 - accuracy: 0.9930\n","Epoch 82/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9930\n","Epoch 83/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0281 - accuracy: 0.9930\n","Epoch 84/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0276 - accuracy: 0.9930\n","Epoch 85/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0274 - accuracy: 0.9930\n","Epoch 86/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0272 - accuracy: 0.9930\n","Epoch 87/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9930\n","Epoch 88/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9930\n","Epoch 89/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0263 - accuracy: 0.9930\n","Epoch 90/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 0.9930\n","Epoch 91/100\n","14/14 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9953\n","Epoch 92/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0255 - accuracy: 0.9930\n","Epoch 93/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0252 - accuracy: 0.9930\n","Epoch 94/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9930\n","Epoch 95/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9930\n","Epoch 96/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0244 - accuracy: 0.9930\n","Epoch 97/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9930\n","Epoch 98/100\n","14/14 [==============================] - 0s 4ms/step - loss: 0.0237 - accuracy: 0.9930\n","Epoch 99/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0234 - accuracy: 0.9930\n","Epoch 100/100\n","14/14 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9930\n","5/5 [==============================] - 0s 3ms/step - loss: 0.1425 - accuracy: 0.9580\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 20)                620       \n","                                                                 \n"," dense_7 (Dense)             (None, 1)                 21        \n","                                                                 \n","=================================================================\n","Total params: 641 (2.50 KB)\n","Trainable params: 641 (2.50 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Loss: 0.14252999424934387\n","Accuracy: 0.9580419659614563\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"R4odOTlXii6f"},"execution_count":null,"outputs":[]}]}